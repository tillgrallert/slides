---
title: "Digital History and the challenges of Data Culture at Humboldt-Universität zu Berlin"
subtitle: ""
author: Till Grallert
institute:
    - "Humboldt-Universität zu Berlin, Institut für Geschichtswissenschaften"
    - "Methods Innovation Lab, NFDI4Memory"
homepage:
event: "Epigraphy.info Workshop VIII"
date: 2024-03-27
url: https://tillgrallert.github.io/slides/...
status: published
lang: de
slide-level: 2
bibliography:
    - https://furesh.github.io/slides/assets/bibliography/FuReSH.csl.json
    - /Users/Shared/HUBox/4memory/Data/bibliography_methods-innovation-lab.csl.json
licence: https://creativecommons.org/licenses/by/4.0/
markdown: pandoc
tags:
    - 4Memory
    - slides
---

# Digital history <br/>what is it and why does it matter?
## The premise of **datafication** and the epoch of computationability

**Datafication** emphasises the epistemic shift from a world were data were a closely defined part of the output of research processes towards the new status quo in which all research processes are always already computationally mediated through information and communication technologies.

::: columns
:::: narrow

[being *digital* has become meaningless]{.keyphrase}

::::
:::: wide

>We think of the 'digital' as a previous historic movement when computation as digitality was understood in opposition to the analogue, rather than complementary [...]

<cite>@Berry+2017, 2</cite>

::::
:::

::: columns
:::: narrow

[*algorithms* as part of the social fabric]{.keyphrase}

::::
:::: wide

>Today, algorithms are such an intrinsic and fundamental part of how daily life is experienced that some scholars even argue that we live in "algorithmic  cultures" [...]. This evocative notion points to the increasing difficulty of separating  algorithms from the activities that make up culture. It also evinces the complex ways in which human agency and algorithmic actions are intertwined [...] 

<cite>@Siles2023Living, 1</cite>

::::
:::


## To make sense of *datafication* we need cultural change within the discipline

::: columns
:::: column

### Staus quo

- very little computational research
- limited understanding of the epistemoloigcal and ontological dimentions of **datafication**
- limited understanding of the concept of **research data** and their enourmous potential for historical research  
- limited practical computational skills
- constantly and rapidly evolving environment -> AI
- resentment towards "the digital"

::::
:::: column

### Aims

- Establish a robust and sustainable **data culture** in order to *emerge from our self-incurred immaturity*
    - make sense of the new episteme
    - develop the necessary skills to conduct historical research
    - negotiate new understandings of history as a discipline

::::
:::

## Data culture

::: columns
:::: column

### broad sense

Data culture as a disciplinary culture, in which (research) data and computational methods form an integral part of historical research and reasoning.

This requires:

- fundamental theoretical, epistemological, and ontological knowledge of *datafication*
- reflection on its implications for all parts of the research process
- ongoing discussion on the necessary changes within the discipline

::::
:::: column

### narrow sense

Data culture as quotidian practices, skill sets, and disciplinary protocolls for handling (research) data and computational research.

This requires:

- orientation
- training
- support 

::::
:::


::: notes

- broad:
    - (research) data cannot, anymore, be perceived as an appendix / addendum to the "actual" research process
- narrow
    - orientation: guidelines, best practices, white papers
        - through and by example
    - training: across the board
    - support: technical, ethical, judicial

:::

## Data, data everywhere



::: columns
:::: column

[All digital information is data]{.keyphrase} ...

::::
:::: column

>Data are forms of information, a larger concept that is even more difficult to define. Epistemological and ontological problems abound, resulting in many books devoted to explicating information and knowledge 

<cite>@Borgman2015BigData, 18</cite>

::::
:::

::: columns
:::: wide

>[Datafication/modeling] is the work of abstracting discrete values from a phenomenon or artifact. These values may be expressed in numbers or texts and are necessarily a reduction of complex materials into a form for computation. <!--With data we can automate processes -->

<cite>@Drucker2021DHCoursebook, 3</cite>

::::
:::: narrow

... and [all data is modelled]{.keyphrase}

- Mapping
- Reduction
- Purpose

::::
:::



::: notes 

- Data literacy as part of data culture
- data re always a concrete embodyment and a socio-technological stack: serialisation
- If we subscribe to social constructivism then all models are historically situated
    - Data and models are situated in historical processes of knowledge production
- Models have three characteristics [@Stachowiak1973AllgemeineModelltheorie]
    - Mapping/ replacing: model for something
    - Reduction: abstracts aspects of interest
    - Purpose: models have a purpose for something
- drucker: capta

:::

# Data culture through examples

# Learning / teaching data culture at the chair of Digital History
## The Name of Things

::: columns
:::: column

### Methods

Named Entity Recognition and the Automatic Recognition of Place and Personal Names in Medieval and Modern Texts

::::
:::: column

### Components

- Definition of NER as Task
- Overview of approaches: 
    - Rule Based
    - Traditional ML
    - Deep Learning
    - LLM
- Challenges of Historical Texts for NER
- Application and Evaluation of various Python Libraries

::::
:::

## Computer Vision

::: columns
:::: column

### Methods

Methods of image recognition and analysis in Digital History

::::
:::: column

### Components

- Computational image analysis
- Theory of deep learning ML
- Application of ready-to-use solutions (YOLO v8, COCO)
- Image annotation and training for detection tasks

::::
:::


## Who wrote it?

::: columns
:::: column

### Methods

Authorship Attribution as a method ofDigital History

::::
:::: column

### Components

- computational text analysis
- Theoretical foundations, comparison of analog and digital methods
- Creation of a silver standard
- Comparison of implementations for authorship analysis

::::
:::

# Conclusion
## Bibliography {#refs}